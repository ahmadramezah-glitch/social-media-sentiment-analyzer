import re
import arabic_reshaper
from bidi.algorithm import get_display
import emoji
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer
from textblob import TextBlob


# Arabic & English Sentiment Words
ARABIC_POSITIVE_WORDS = {
    'Ù…Ù…ØªØ§Ø²', 'Ø±Ø§Ø¦Ø¹', 'Ø¬Ù…ÙŠÙ„', 'Ø¹Ø¸ÙŠÙ…', 'Ù…Ø°Ù‡Ù„', 'Ù…ÙÙŠØ¯', 'Ø¬ÙŠØ¯', 'Ø­Ù„Ùˆ', 'Ù„Ø°ÙŠØ°', 'Ù…Ø±ÙŠØ­',
    'Ø³Ø¹ÙŠØ¯', 'ÙØ±Ø­Ø§Ù†', 'Ù…Ø¨Ø³ÙˆØ·', 'Ù…ØªØ­Ù…Ø³', 'Ù…Ø´Ø¬Ø¹', 'Ù…Ù…ØªØ§Ø²Ø©', 'Ø±Ø§Ø¦Ø¹Ø©', 'Ø¬Ù…ÙŠÙ„Ø©', 'Ø¹Ø¸ÙŠÙ…Ø©',
    'Ù…Ø°Ù‡Ù„Ø©', 'Ù…ÙÙŠØ¯Ø©', 'Ø¬ÙŠØ¯Ø©', 'Ø­Ù„ÙˆØ©', 'Ù„Ø°ÙŠØ°Ø©', 'Ù…Ø±ÙŠØ­Ø©', 'Ø³Ø¹ÙŠØ¯Ø©', 'ÙØ±Ø­Ø§Ù†Ø©', 'Ù…Ø¨Ø³ÙˆØ·Ø©',
    'Ù…ØªØ­Ù…Ø³Ø©', 'Ù…Ø´Ø¬Ø¹Ø©', 'Ø£ÙØ¶Ù„', 'Ø£Ø­Ø³Ù†', 'Ø£Ø¬Ù…Ù„', 'Ø£Ø±ÙˆØ¹', 'Ø£Ù…ØªØ¹', 'Ø£Ù„Ø°', 'Ø£Ø­Ù„Ù‰',
    'Ø³Ø±ÙŠØ¹', 'Ø³Ø±ÙŠØ¹Ø©', 'Ø£Ø³Ø±Ø¹', 'Ø£Ø³Ø±Ø¹', 'Ø¨ÙŠÙ†Ø§Ø³Ø¨', 'Ù…Ù†Ø§Ø³Ø¨', 'Ù…Ù†Ø§Ø³Ø¨Ø©', 'Ø£ÙØ¶Ù„', 'Ø£Ø­Ø³Ù†',
    'Ù…Ù…ØªØ§Ø²', 'Ø±Ø§Ø¦Ø¹', 'Ø¬Ù…ÙŠÙ„', 'Ø¹Ø¸ÙŠÙ…', 'Ù…Ø°Ù‡Ù„', 'Ù…ÙÙŠØ¯', 'Ø¬ÙŠØ¯', 'Ø­Ù„Ùˆ', 'Ù„Ø°ÙŠØ°', 'Ù…Ø±ÙŠØ­',
    'excellent', 'amazing', 'great', 'good', 'wonderful', 'fantastic', 'awesome',
    'beautiful', 'nice', 'perfect', 'love', 'like', 'enjoy', 'happy', 'excited',
    'brilliant', 'outstanding', 'superb', 'magnificent', 'splendid', 'marvelous',
    'delightful', 'pleasing', 'satisfying', 'enjoyable', 'pleasurable', 'grateful',
    'thankful', 'blessed', 'fortunate', 'lucky', 'successful', 'winning', 'victorious',
    'fast', 'fastest', 'quick', 'quickest', 'speedy', 'rapid', 'swift', 'efficient',
    'convenient', 'suitable', 'appropriate', 'ideal', 'perfect', 'best', 'optimal',
    'affordable', 'cheap', 'inexpensive', 'reasonable', 'value', 'deal', 'offer',
    'service', 'broadband', 'wifi', 'internet', 'connection', 'available', 'ready'
}

ARABIC_NEGATIVE_WORDS = {
    'Ø³ÙŠØ¡', 'Ø±Ø¯ÙŠØ¡', 'Ù…Ø²Ø¹Ø¬', 'Ù…Ø¤Ù„Ù…', 'Ù…Ø®ÙŠØ¨', 'Ø³ÙŠØ¦Ø©', 'Ø±Ø¯ÙŠØ¦Ø©', 'Ù…Ø²Ø¹Ø¬Ø©', 'Ù…Ø¤Ù„Ù…Ø©',
    'Ù…Ø®ÙŠØ¨Ø©', 'Ø£Ø³ÙˆØ£', 'Ø£Ø±Ø¯Ø£', 'Ø£Ù…Ø²Ø¹Ø¬', 'Ø£Ù…Ø¤Ù„Ù…', 'Ø£Ù…Ø®ÙŠØ¨', 'Ù…ÙƒØ±ÙˆÙ‡', 'Ù…Ø¨ØºÙˆØ¶', 'Ù…Ù‚Ø±Ù',
    'Ù…Ù‚Ø²Ø²', 'Ù…Ø«ÙŠØ± Ù„Ù„Ø§Ø´Ù…Ø¦Ø²Ø§Ø²', 'Ù…Ø®Ø¬Ù„', 'Ù…Ø®Ø²', 'Ù…Ø®ÙŠØ¨ Ù„Ù„Ø£Ù…Ù„', 'Ù…Ø­Ø¨Ø·', 'Ù…Ø­Ø¨Ø·Ø©',
    'bad', 'terrible', 'awful', 'horrible', 'disgusting', 'hate', 'dislike',
    'annoying', 'frustrating', 'disappointing', 'sad', 'angry', 'upset', 'dreadful',
    'atrocious', 'appalling', 'revolting', 'repulsive', 'nauseating', 'sickening',
    'offensive', 'insulting', 'humiliating', 'embarrassing', 'shameful', 'disgraceful',
    'unpleasant', 'uncomfortable', 'painful', 'hurtful', 'harmful', 'damaging',
    'destructive', 'ruinous', 'catastrophic', 'devastating', 'crushing', 'overwhelming'
}

# Emoji sentiment score dictionary
EMOJI_SENTIMENT = {
    # Very Positive
    'ðŸ˜': 1.0, 'ðŸ¥°': 1.0, 'â¤ï¸': 1.0, 'ðŸ’–': 1.0, 'ðŸ’•': 1.0, 'ðŸ’—': 1.0, 'ðŸ’“': 1.0,
    'ðŸ¤©': 0.9, 'ðŸ˜Š': 0.9, 'ðŸ˜': 0.9, 'ðŸ˜„': 0.9, 'ðŸ™Œ': 0.9, 'ðŸ‘': 0.9, 'ðŸŽ‰': 0.9,
    
    # Positive
    'ðŸ˜Š': 0.8, 'ðŸ˜‚': 0.8, 'ðŸ˜Ž': 0.8, 'ðŸ‘': 0.8, 'ðŸ˜ƒ': 0.8, 'ðŸ˜†': 0.8, 'ðŸ˜‰': 0.8,
    'ðŸ˜‹': 0.8, 'ðŸ˜Œ': 0.8, 'ðŸ˜‡': 0.8, 'ðŸ¤—': 0.8, 'ðŸ¤”': 0.6, 'ðŸ¤“': 0.7, 'ðŸ˜': 0.5,
    
    # Neutral
    'ðŸ˜': 0.0, 'ðŸ˜‘': 0.0, 'ðŸ˜¶': 0.0, 'ðŸ¤': 0.0, 'ðŸ˜¯': 0.0, 'ðŸ˜¦': 0.0, 'ðŸ˜§': 0.0,
    'ðŸ˜®': 0.0, 'ðŸ˜²': 0.0, 'ðŸ˜´': 0.0, 'ðŸ¤¤': 0.0, 'ðŸ˜ª': 0.0, 'ðŸ˜µ': 0.0, 'ðŸ¤¢': 0.0,
    
    # Negative
    'ðŸ˜¢': -0.6, 'ðŸ˜ž': -0.6, 'ðŸ˜”': -0.6, 'ðŸ˜©': -0.6, 'ðŸ˜¤': -0.6, 'ðŸ˜£': -0.6,
    'ðŸ˜–': -0.6, 'ðŸ˜«': -0.6, 'ðŸ˜“': -0.6, 'ðŸ˜¥': -0.6, 'ðŸ˜°': -0.6, 'ðŸ˜¨': -0.6,
    
    # Very Negative
    'ðŸ˜¡': -0.9, 'ðŸ˜ ': -0.9, 'ðŸ˜¤': -0.9, 'ðŸ˜­': -0.9, 'ðŸ‘Ž': -0.9, 'ðŸ’”': -1.0,
    'ðŸ˜ˆ': -0.8, 'ðŸ‘¿': -0.8, 'ðŸ˜±': -0.8, 'ðŸ˜¨': -0.8, 'ðŸ˜°': -0.8, 'ðŸ˜¥': -0.8,
    
    # Additional positive emojis
    'âœ¨': 0.8, 'ðŸŒŸ': 0.8, 'ðŸ’«': 0.8, 'â­': 0.8, 'ðŸ”¥': 0.8, 'ðŸ’¯': 0.9, 'ðŸ’ª': 0.8,
    'ðŸ†': 0.9, 'ðŸŽ¯': 0.8, 'ðŸŽŠ': 0.8, 'ðŸŽˆ': 0.7, 'ðŸŽ': 0.8, 'ðŸŽ‚': 0.7, 'ðŸ°': 0.7,
    
    # Additional negative emojis
    'ðŸ’©': -0.8, 'ðŸ‘»': -0.3, 'â˜ ï¸': -0.9, 'ðŸ’€': -0.8, 'ðŸ‘¹': -0.8, 'ðŸ‘º': -0.8,
    'ðŸ˜ˆ': -0.8, 'ðŸ‘¿': -0.8, 'ðŸ¤¡': -0.5, 'ðŸ‘½': -0.3, 'ðŸ¤–': -0.2, 'ðŸ‘¾': -0.2
}

# Initialize sentiment analyzers
vader_analyzer = None
try:
    # Try to initialize VADER analyzer without downloading
    vader_analyzer = SentimentIntensityAnalyzer()
    print("NLTK sentiment analyzer loaded successfully!")
except Exception as e:
    print(f"Error loading NLTK: {e}")
    vader_analyzer = None

# Initialize sentiment analyzer
sentiment_analyzer = None

# Simple sentiment analysis using keyword matching
def advanced_sentiment_analysis(text):
    """Advanced sentiment analysis using NLTK VADER and TextBlob for comprehensive word understanding"""
    if not text:
        return "neutral", 0.0
    
    # Clean the text
    cleaned_text = clean_text(text)
    if not cleaned_text:
        return "neutral", 0.0
    
    # Initialize scores
    vader_score = 0.0
    textblob_score = 0.0
    emoji_score = 0.0
    emoji_count = 0
    keyword_score = 0.0
    
    # Analyze emojis first
    for emoji_char, score in EMOJI_SENTIMENT.items():
        if emoji_char in text:
            emoji_score += score
            emoji_count += 1
    
    # Calculate average emoji sentiment if emojis found
    if emoji_count > 0:
        emoji_score = emoji_score / emoji_count
    
    # Analyze keywords for Arabic and English
    text_lower = text.lower()
    positive_count = 0
    negative_count = 0
    
    # Check for positive keywords
    for word in ARABIC_POSITIVE_WORDS:
        if word.lower() in text_lower:
            positive_count += 1
    
    # Check for negative keywords
    for word in ARABIC_NEGATIVE_WORDS:
        if word.lower() in text_lower:
            negative_count += 1
    
    # Calculate keyword score
    if positive_count > 0 or negative_count > 0:
        keyword_score = (positive_count - negative_count) / max(positive_count + negative_count, 1)
        keyword_score = max(-0.9, min(0.9, keyword_score))
    
    # Use NLTK VADER for English text analysis
    if vader_analyzer:
        try:
            vader_scores = vader_analyzer.polarity_scores(cleaned_text)
            vader_score = vader_scores['compound']  # Compound score ranges from -1 to 1
        except Exception as e:
            print(f"VADER analysis error: {e}")
            vader_score = 0.0
    
    # Use TextBlob for additional analysis
    try:
        blob = TextBlob(cleaned_text)
        textblob_score = blob.sentiment.polarity  # Ranges from -1 to 1
    except Exception as e:
        print(f"TextBlob analysis error: {e}")
        textblob_score = 0.0
    
    # Combine scores with weights
    # VADER: 30%, TextBlob: 25%, Emojis: 25%, Keywords: 20%
    combined_score = (vader_score * 0.3) + (textblob_score * 0.25) + (emoji_score * 0.25) + (keyword_score * 0.2)
    
    # Context-aware adjustments for promotional content
    text_lower = text.lower()
    
    # Check for promotional indicators (positive boost)
    promotional_indicators = [
        'fastest', 'best', 'perfect', 'ideal', 'optimal', 'excellent', 'amazing',
        'great', 'wonderful', 'fantastic', 'awesome', 'brilliant', 'outstanding',
        'superb', 'magnificent', 'splendid', 'marvelous', 'delightful', 'pleasing',
        'satisfying', 'enjoyable', 'pleasurable', 'grateful', 'thankful', 'blessed',
        'fortunate', 'lucky', 'successful', 'winning', 'victorious', 'fast', 'quick',
        'speedy', 'rapid', 'swift', 'efficient', 'convenient', 'suitable', 'appropriate',
        'affordable', 'cheap', 'inexpensive', 'reasonable', 'value', 'deal', 'offer',
        'service', 'broadband', 'wifi', 'internet', 'connection', 'available', 'ready',
        'Ø³Ø±ÙŠØ¹', 'Ø³Ø±ÙŠØ¹Ø©', 'Ø£Ø³Ø±Ø¹', 'Ø¨ÙŠÙ†Ø§Ø³Ø¨', 'Ù…Ù†Ø§Ø³Ø¨', 'Ù…Ù†Ø§Ø³Ø¨Ø©', 'Ø£ÙØ¶Ù„', 'Ø£Ø­Ø³Ù†', 'Ù…Ù…ØªØ§Ø²',
        'Ø±Ø§Ø¦Ø¹', 'Ø¬Ù…ÙŠÙ„', 'Ø¹Ø¸ÙŠÙ…', 'Ù…Ø°Ù‡Ù„', 'Ù…ÙÙŠØ¯', 'Ø¬ÙŠØ¯', 'Ø­Ù„Ùˆ', 'Ù„Ø°ÙŠØ°', 'Ù…Ø±ÙŠØ­'
    ]
    
    promotional_count = sum(1 for word in promotional_indicators if word in text_lower)
    if promotional_count > 0:
        # Boost positive sentiment for promotional content
        combined_score += (promotional_count * 0.1)
        combined_score = min(0.9, combined_score)  # Cap at 0.9
    
    # Determine sentiment and polarity
    if combined_score > 0.05:  # Lowered threshold for positive
        sentiment = "positive"
        polarity = min(0.9, combined_score)
    elif combined_score < -0.05:  # Lowered threshold for negative
        sentiment = "negative"
        polarity = max(-0.9, combined_score)
    else:
        sentiment = "neutral"
        polarity = 0.0
    
    return sentiment, polarity

def simple_sentiment_analysis(text):
    """Fallback sentiment analysis using keyword matching and emoji analysis"""
    if not text:
        return "neutral", 0.0
    
    text_lower = text.lower()
    
    # Positive keywords
    positive_words = ['good', 'great', 'amazing', 'excellent', 'wonderful', 'fantastic', 'love', 'like', 'awesome', 'perfect', 'best', 'beautiful', 'nice', 'happy', 'joy', 'excited', 'wow', 'Ù…Ù…ØªØ§Ø²', 'Ø±Ø§Ø¦Ø¹', 'Ø¬Ù…ÙŠÙ„', 'Ø¹Ø¸ÙŠÙ…', 'Ù…Ø°Ù‡Ù„']
    
    # Negative keywords  
    negative_words = ['bad', 'terrible', 'awful', 'hate', 'dislike', 'worst', 'horrible', 'disappointing', 'sad', 'angry', 'frustrated', 'upset', 'Ø³ÙŠØ¡', 'Ù…Ø®ÙŠØ¨', 'Ù…Ø²Ø¹Ø¬', 'Ù…Ø­Ø¨Ø·']
    
    # Count keyword matches
    positive_count = sum(1 for word in positive_words if word in text_lower)
    negative_count = sum(1 for word in negative_words if word in text_lower)
    
    # Analyze emojis
    emoji_score = 0.0
    emoji_count = 0
    
    for emoji_char, score in EMOJI_SENTIMENT.items():
        if emoji_char in text:
            emoji_score += score
            emoji_count += 1
    
    # Calculate average emoji sentiment if emojis found
    if emoji_count > 0:
        emoji_score = emoji_score / emoji_count
        # Convert emoji score to count (positive emojis add to positive count, negative to negative)
        if emoji_score > 0:
            positive_count += abs(emoji_score) * 2  # Weight emojis more heavily
        elif emoji_score < 0:
            negative_count += abs(emoji_score) * 2
    
    # Calculate sentiment
    if positive_count > negative_count:
        sentiment = "positive"
        polarity = min(0.9, positive_count / 8)  # Adjusted for emoji influence
    elif negative_count > positive_count:
        sentiment = "negative" 
        polarity = max(-0.9, -negative_count / 8)
    else:
        sentiment = "neutral"
        polarity = 0.0
    
    return sentiment, polarity

def clean_text(text):
    """Clean and normalize text for sentiment analysis"""
    if not text:
        return ""
    
    # Convert to string if not already
    text = str(text)
    
    # Handle Arabic text
    text = arabic_reshaper.reshape(text)
    text = get_display(text)
    
    # Keep emojis for sentiment analysis (don't demojize)
    # text = emoji.demojize(text)  # Commented out to preserve emojis
    
    # Remove URLs
    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
    
    # Remove hashtags but keep the text
    text = re.sub(r'#(\w+)', r'\1', text)
    
    # Remove mentions
    text = re.sub(r'@(\w+)', '', text)
    
    # Remove extra whitespace
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def analyze_sentiment(text):
    """Analyze sentiment using advanced analysis and return sentiment and polarity score"""
    try:
        # Clean the text
        cleaned_text = clean_text(text)
        
        if not cleaned_text:
            return "neutral", 0.0
        
        # Try advanced analysis first (NLTK + TextBlob + Emojis)
        if vader_analyzer:
            sentiment, polarity = advanced_sentiment_analysis(text)
        else:
            # Fallback to simple analysis
            sentiment, polarity = simple_sentiment_analysis(cleaned_text)
        
        return sentiment, polarity
        
    except Exception as e:
        print(f"Error in sentiment analysis: {e}")
        return "neutral", 0.0

def get_sentiment_confidence(text):
    """Get sentiment confidence score for visualization"""
    try:
        cleaned_text = clean_text(text)
        if not cleaned_text:
            return 0.0
        
        # Use the same analysis method as analyze_sentiment
        if vader_analyzer:
            sentiment, polarity = advanced_sentiment_analysis(text)
        else:
            sentiment, polarity = simple_sentiment_analysis(cleaned_text)
        
        return abs(polarity)
        
    except Exception as e:
        print(f"Error getting sentiment confidence: {e}")
        return 0.0

def get_sentiment_color(sentiment, confidence=1.0):
    """Get color for sentiment visualization"""
    if sentiment == "positive":
        return f"rgba(34, 197, 94, {confidence})"  # Green
    elif sentiment == "negative":
        return f"rgba(239, 68, 68, {confidence})"  # Red
    else:
        return f"rgba(156, 163, 175, {confidence})"  # Gray

def get_sentiment_bar_width(polarity):
    """Convert polarity to bar width percentage"""
    # Convert polarity (-1 to 1) to percentage (0 to 100)
    return abs(polarity) * 100
